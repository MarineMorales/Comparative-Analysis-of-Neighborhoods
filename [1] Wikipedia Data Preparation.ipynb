{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b4c733-7da6-4dff-ba3d-fe89c504200d",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Neighborhoods | Wikipedia Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3414941-d46a-48ff-b454-163acc5692e2",
   "metadata": {},
   "source": [
    "We will format our wikipedia pages listing the most up to date postal codes, neighborhoods and boroughs of the cities we want to investigate.\n",
    "- Halifax: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_B\n",
    "- Quebec City: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_G\n",
    "- Montreal: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_H\n",
    "- Ottawa: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_K\n",
    "- Toronto: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n",
    "- Vancouver: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_V\n",
    "- Paris: https://fr.geneawiki.com/wiki/Liste_des_quartiers_de_Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f5c6c-488c-4c42-a6d8-685ba89d7268",
   "metadata": {},
   "source": [
    "## [1] Working environment set up\n",
    "\n",
    "Before starting, we need to install and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4a5d64-7d28-4696-8a68-c072842567bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Data Access and Web Scraping\n",
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "!pip install requests\n",
    "import requests\n",
    "\n",
    "# Data Storage and File Handling\n",
    "import json\n",
    "#from pandas import json_normalize\n",
    "#!pip install openpyxl\n",
    "!pip install lxml\n",
    "import xml\n",
    "import zipfile\n",
    "#from io import BytesIO, StringIO\n",
    "\n",
    "# Data Manipulation and Processing\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import re\n",
    "#import unicodedata\n",
    "#!pip install unidecode\n",
    "#import unidecode\n",
    "#!pip install fuzzywuzzy\n",
    "#from fuzzywuzzy import fuzz\n",
    "#from fuzzywuzzy import process\n",
    "#from difflib import get_close_matches\n",
    "\n",
    "# Geolocation and Mapping\n",
    "#!pip install geocoder\n",
    "#import geocoder\n",
    "#!pip install geopy\n",
    "#from geopy.geocoders import Nominatim \n",
    "#from geopy.distance import geodesic\n",
    "\n",
    "# Statistical Analysis and Clustering\n",
    "#from scipy import stats\n",
    "#import researchpy as rp\n",
    "#!pip install scikit-learn\n",
    "#from sklearn.cluster import KMeans\n",
    "\n",
    "# Data Visualization\n",
    "#!pip install matplotlib\n",
    "#import matplotlib.cm as cm\n",
    "#import matplotlib.colors as colors\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#import seaborn as sns\n",
    "#!pip install folium\n",
    "#import folium\n",
    "\n",
    "# Display and Configuration\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.expand_frame_repr', False)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "# Miscellaneous\n",
    "#import time\n",
    "#from IPython.display import display\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37dd18-32fd-402e-91df-501b56cdde4a",
   "metadata": {},
   "source": [
    "## [2] User Input\n",
    "\n",
    "Save the wikipedia pages data for future selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a1c243-4000-4b4c-bcc4-0cad10b15e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the wikipedia pages into a dictionary and transform it into a dataframe\n",
    "citiesinfo_dic = {\n",
    "    'city0': ['Quebec City', 'Montreal', 'Ottawa', 'Toronto', 'Vancouver', 'Paris'],\n",
    "    'city1': ['Quebec City, Quebec', 'Montreal, Quebec', 'Ottawa, Ontario', \n",
    "              'Toronto, Ontario', 'Vancouver, British Columbia', 'Paris, France'],\n",
    "    'city2': ['Quebec City, QC', 'Montreal, QC', 'Ottawa, ON', \n",
    "              'Toronto, ON', 'Vancouver, BC', 'Paris, France'],\n",
    "    'test1': ['G3N', 'H3A', 'K2C', 'M4G', 'V5A','75003'],\n",
    "    'url': [\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_G',\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_H',\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_K',\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M',\n",
    "        'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_V',\n",
    "        'https://fr.geneawiki.com/wiki/Liste_des_quartiers_de_Paris'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca313918-4da3-4159-b73f-616c992d15c4",
   "metadata": {},
   "source": [
    "## [3] Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef616311-6a1d-4272-a489-0270173daa53",
   "metadata": {},
   "source": [
    "To be able to extract the data from our wikipedia sources, it’s crucial to first understand the type of data we need to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8404b750-8496-4f67-9d3e-b0a6404f75cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: Quebec City - Type of url_data: <class 'list'>\n",
      "City: Montreal - Type of url_data: <class 'list'>\n",
      "City: Ottawa - Type of url_data: <class 'list'>\n",
      "City: Toronto - Type of url_data: <class 'list'>\n",
      "City: Vancouver - Type of url_data: <class 'list'>\n",
      "City: Paris - Type of url_data: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for city, url in zip(citiesinfo_dic['city0'], citiesinfo_dic['url']):\n",
    "    url_data = pd.read_html(url)\n",
    "    print(f\"City: {city} - Type of url_data: {type(url_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5775b-c945-401e-ab92-0b310131b0a3",
   "metadata": {},
   "source": [
    "Now we know it is a list, we can scrap the postal codes from the url page with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14208b9d-0daa-40d4-ad8b-b9fb6745c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Quebec City stored successfully.\n",
      "Data for Montreal stored successfully.\n",
      "Data for Ottawa stored successfully.\n",
      "Data for Toronto stored successfully.\n",
      "Data for Vancouver stored successfully.\n",
      "Data for Paris stored successfully.\n"
     ]
    }
   ],
   "source": [
    "citiesinfo_dic['soup'] = []\n",
    "for city, url in zip(citiesinfo_dic['city0'], citiesinfo_dic['url']):\n",
    "    try:\n",
    "        # Fetch the HTML content of the page\n",
    "        extracted_data = requests.get(url).text\n",
    "        \n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = BeautifulSoup(extracted_data, 'lxml') # lxml is more powerful than html.parser\n",
    "\n",
    "        # Store the parsed BeautifulSoup object in the dictionary for further analysis\n",
    "        citiesinfo_dic['soup'].append(soup)\n",
    "        print(f\"Data for {city} stored successfully.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Handle any errors encountered\n",
    "        print(f\"An error occurred at URL: {city}: {e}\")\n",
    "        citiesinfo_dic['soup'].append(None)  # Store None if there's an error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102945b-7801-4bb5-8e6d-021b3034067d",
   "metadata": {},
   "source": [
    "Let's preview of a compartment block of data from the wikipedia page to clarify how we can scrap the different information we need from it: Postal codes, borough and neighborhoods."
   ]
  },
  {
   "cell_type": "raw",
   "id": "108574cb-6f58-4a1c-81ee-353f2ce34f4f",
   "metadata": {},
   "source": [
    "# Quebec city compartment block\n",
    ".prettify()[43050:43490])\n",
    "# Toronto compartment block\n",
    ".prettify()[50420:51150]\n",
    "# Vancouver compartment block\n",
    ".prettify()[45900:46680]\n",
    "# Montreal compartment block\n",
    ".prettify()[50820:51210]\n",
    "# Paris compartment block\n",
    ".prettify()[15770:17263]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee47e6-595c-43a1-99dc-8edcf5b159fa",
   "metadata": {},
   "source": [
    "Not to overcrowed with information this notebook, I will only call the information from the Parisian data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af851702-0ea3-4599-9d89-68a219f8a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       </div>\n",
      "         <table cellpadding=\"2\" cellspacing=\"0\" rules=\"all\" style=\"border-collapse: collapse; border: 1px solid #ccc;\" width=\"100%\">\n",
      "          <tbody>\n",
      "           <tr>\n",
      "            <td valign=\"top\" width=\"11.1%\">\n",
      "             <b>\n",
      "              G1A\n",
      "             </b>\n",
      "             <br/>\n",
      "             <span style=\"font-size: smaller; line-height: 125%;\">\n",
      "              <a href=\"/wiki/Quebec_City\" title=\"Quebec City\">\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "print(citiesinfo_dic['soup'][citiesinfo_dic['city0'].index(\"Quebec City\")].prettify()[43050:43490])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a02e03-e78c-478b-a5ad-709a4ff403f5",
   "metadata": {},
   "source": [
    "List the postal codes to investigate in the wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979602f7-1c84-4eee-b75b-04a154bfea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quebec City: 200 postal codes extracted.\n",
      "Montreal: 180 postal codes extracted.\n",
      "Ottawa: 160 postal codes extracted.\n",
      "Toronto: 97 postal codes extracted.\n",
      "Vancouver: 200 postal codes extracted.\n",
      "Paris: 20 postal codes extracted.\n"
     ]
    }
   ],
   "source": [
    "# Create a function to extract the list of postal codes for Paris\n",
    "def extract_french_postal_codes(soup):\n",
    "    postalcodes_list = []\n",
    "    for tr in soup.find_all('tr'):\n",
    "        postalcodes_elements = tr.find_all('td', align=\"center\") # Get all the <td> elements within the row\n",
    "        if len(postalcodes_elements) >= 2: # Ensure the row contains at least two <td> elements\n",
    "            postalcode = postalcodes_elements[1].text.strip()\n",
    "            if postalcode.isdigit() and len(postalcode) == 5: # Append only valid 5-digit postal codes\n",
    "                postalcodes_list.append(postalcode)\n",
    "    return postalcodes_list\n",
    "\n",
    "# Create a function to extract the list of postal codes for canadian cities\n",
    "def extract_canadian_postal_codes(soup):\n",
    "    postalcodes_elements = soup.find_all('td', {'style': 'vertical-align:top;'}) + soup.find_all('td', {'valign': 'top'})\n",
    "    postalcodes_list = [td.find('b').text.strip() for td in postalcodes_elements if td.find('b')]\n",
    "    return postalcodes_list\n",
    "\n",
    "def extract_postal_codes(city, soup):\n",
    "    return extract_french_postal_codes(soup) if city == 'Paris' else extract_canadian_postal_codes(soup)\n",
    "\n",
    "# Add a new key 'postal_codes' to wiki_dic and store the parsed data with postal codes\n",
    "citiesinfo_dic['postal_codes'] = [\n",
    "    extract_postal_codes(city, soup) if soup else []\n",
    "    for city, soup in zip(citiesinfo_dic['city0'], citiesinfo_dic['soup'])\n",
    "]\n",
    "\n",
    "# Display summary of extracted postal codes\n",
    "for city, postal_codes in zip(citiesinfo_dic['city0'], citiesinfo_dic['postal_codes']):\n",
    "    print(f\"{city}: {len(postal_codes)} postal codes extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347f2aa-c789-4ee3-a856-2f1b36cd60c7",
   "metadata": {},
   "source": [
    "We will use the following methodology to retrieve the postal codes, borough and neighborhoods from the html data:\n",
    "- **Compartment**: to investigate all the information assigned to a single postal code, I will need to isolate the *[td]* tags for Canada and the *[tr]* tags for France.\n",
    "- **Postal Code**: to extract the postal codes, I will check within the *[b]* tags of each compartments in Canada and within the *[td]* tags for France.\n",
    "- **Borough**: to extract the borough, I will first check for both the *[span]* and *[a]* tags. Only process the postal codes that have an assigned borough.\n",
    "- **Neighborhoods**: to extract the neighborhoods, I will stop at each *[a]* tag (excluding the first one linked to the Borough) for Canada and at each *[dd]* tag for Paris. Indeed, more than one neighborhood can exist in one postal code area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e8e3a5-f81d-49dc-8fca-f7353e78246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to extract the french data\n",
    "def extract_french_data(soup):\n",
    "    city_data = []\n",
    "    # [Compartment]\n",
    "    for tr in soup.find_all('tr'):\n",
    "        # [Postal Code]\n",
    "        postalcode_element = tr.find_all('td', align=\"center\")\n",
    "        postalcode = (postalcode_element[1].text.strip() if len(postalcode_element) >= 2\n",
    "                                                            and postalcode_element[1].text.strip().isdigit()\n",
    "                                                            and len(postalcode_element[1].text.strip()) == 5\n",
    "                                                        else None)\n",
    "        if postalcode:\n",
    "            # [Borough]\n",
    "            borough = tr.find('a', title=True).text.strip() if tr.find('a', title=True) else \"Unknown\"\n",
    "            # [Neighborhoods]\n",
    "            neighborhoods_list = [n.find('a').text.strip() if n.find('a') else n.text.strip().split(' - ')[-1] for n in tr.find_all('dd')]\n",
    "            neighborhood = ', '.join(neighborhoods_list) if neighborhoods_list else \"Unknown\"\n",
    "            # [Append the final result]\n",
    "            city_data.append({'Postalcode': postalcode, 'Borough': borough, 'Neighborhood': neighborhood})\n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6804f4e9-998c-47d1-b53d-4a1030e33080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to extract the canadian data\n",
    "def extract_canadian_data(soup, city):\n",
    "    city_data = []\n",
    "    # Define cardinal directions to check\n",
    "    cardinal_directions_list = [\"north\", \"south\", \"east\", \"west\", \"northeast\", \"northwest\", \"southeast\", \"southwest\", \"central\"]\n",
    "    # Create a tuple of cardinal directions with a space after each for the startswith check\n",
    "    cardinal_directions_tuple = tuple(direction + \" \" for direction in cardinal_directions_list)\n",
    "    # [Compartment]\n",
    "    for td in soup.find_all('td', {'style': 'vertical-align:top;'}) + soup.find_all('td', {'valign': 'top'}):\n",
    "        # [Postal Code]\n",
    "        postalcode = td.find('b').text.strip() if td.find('b') else None\n",
    "        if postalcode:\n",
    "            # [Borough]\n",
    "            span = td.find('span')\n",
    "            borough = span.find('a').text.strip() if span and span.find('a') else \"Unknown\"\n",
    "            \n",
    "            # [Neighborhoods]\n",
    "            neighborhood_text = span.text if span else \"\"\n",
    "            neighborhoods_list = [a.text.strip() for a in span.find_all('a')[1:]] if span else []\n",
    "            # Fallback if neighborhoods list is empty\n",
    "            if not neighborhoods_list:\n",
    "                neighborhood_text = span.get_text(strip=True) if span else \"\"\n",
    "                neighborhoods_list = [neighborhood_text.strip()]\n",
    "            # Build the neighborhood string with cardinal direction handling\n",
    "            neighborhood = ', '.join(neighborhoods_list).strip()\n",
    "            # Clean up the neighborhood: remove parentheses and check for empty values\n",
    "            neighborhood = re.sub(r\"[()]\", \" \", neighborhood).strip()\n",
    "            # Remove borough from neighborhood only if it starts with it and there’s no cardinal direction\n",
    "            if neighborhood.startswith(borough) and not any(n.lower() in cardinal_directions_list for n in neighborhoods_list):\n",
    "                neighborhood = neighborhood[len(borough):].strip()\n",
    "            # Handle cases where neighborhood is just a direction\n",
    "            if neighborhood.lower() in cardinal_directions_list:\n",
    "                neighborhood = f\"{borough} {neighborhood}\"\n",
    "            # Set neighborhood to \"Unknown\" if it's empty or invalid\n",
    "            if not neighborhood or neighborhood in {\"\", \"[\", \"]\", \")\", \"(\", \",\", \"Unknown\"} or neighborhood.lower() == \"unknown\":\n",
    "                neighborhood = borough\n",
    "            # Ensure borough names are unique enough\n",
    "            if borough == city or borough.lower() == \"unknown\":\n",
    "                borough = neighborhood.split(',', 1)[0].strip() + \" & co\" if ',' in neighborhood else neighborhood\n",
    "            # If neighborhood starts or ends with a hyphen, prepend or append borough as needed\n",
    "            if neighborhood.startswith('-'):\n",
    "                neighborhood = f\"{borough} {neighborhood.lstrip('-').strip()}\".replace(' ', '-')\n",
    "            elif neighborhood.endswith('-'):\n",
    "                neighborhood = f\"{neighborhood.rstrip('-').strip()} {borough}\".replace(' ', '-')\n",
    "            # [Append the final result]\n",
    "            city_data.append({'Postalcode': postalcode, 'Borough': borough, 'Neighborhood': neighborhood})\n",
    "    \n",
    "    return city_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb1622e-00ee-427e-86d4-ce6419ade128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted for Quebec City.\n",
      "Data extracted for Montreal.\n",
      "Data extracted for Ottawa.\n",
      "Data extracted for Toronto.\n",
      "Data extracted for Vancouver.\n",
      "Data extracted for Paris.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the 'extracted_data' field in cityinfo_dic to store results for each city\n",
    "citiesinfo_dic['extracted_data'] = []\n",
    "\n",
    "# Iterate over each city in wiki_dic to extract and store data\n",
    "for city, soup in zip(citiesinfo_dic['city0'], citiesinfo_dic['soup']):\n",
    "    if soup:\n",
    "        extracted_data = extract_french_data(soup) if city == 'Paris' else extract_canadian_data(soup, city)\n",
    "        citiesinfo_dic['extracted_data'].append(extracted_data)\n",
    "        print(f\"Data extracted for {city}.\")\n",
    "    else:\n",
    "        citiesinfo_dic['extracted_data'].append([])\n",
    "        print(f\"No data available for {city}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d6c3e-dcae-4ab8-84bd-17abc584a861",
   "metadata": {},
   "source": [
    "Transform the retrieved data into a dataframe and check that we could retrieve all the postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b21945-394d-43d0-8971-5b293278ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the count of rows in our DataFrame with the count of postal codes in the Wikipedia source:\n",
      "Quebec City: Matched (200)\n",
      "Montreal: Matched (180)\n",
      "Ottawa: Matched (160)\n",
      "Toronto: Matched (97)\n",
      "Vancouver: Matched (200)\n",
      "Paris: Matched (20)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to hold all data with city information\n",
    "all_data = []\n",
    "\n",
    "# Iterate over each city and add the city name to each extracted row\n",
    "for city, city1, city2, extracted_data in zip(citiesinfo_dic['city0'], citiesinfo_dic['city1'], citiesinfo_dic['city2'], citiesinfo_dic['extracted_data']):\n",
    "    # Add the city name to each entry in extracted_data\n",
    "    for row in extracted_data:\n",
    "        row['City'] = city\n",
    "        row['City1'] = city1\n",
    "        row['City2'] = city2\n",
    "        all_data.append(row)\n",
    "\n",
    "# Create a dataframe from the rows\n",
    "cities_df = pd.DataFrame(all_data)\n",
    "\n",
    "# Check row counts for consistency\n",
    "print(\"Comparing the count of rows in our DataFrame with the count of postal codes in the Wikipedia source:\")\n",
    "for city in citiesinfo_dic['city0']:\n",
    "    city_rows_count = cities_df[cities_df['City'] == city].shape[0]\n",
    "    postal_codes_count = len(citiesinfo_dic['postal_codes'][citiesinfo_dic['city0'].index(city)])\n",
    "    if city_rows_count == postal_codes_count:\n",
    "        print(f\"{city}: Matched ({city_rows_count})\")\n",
    "    else:\n",
    "        print(f\"{city}: Mismatch (DataFrame: {city_rows_count}, Source: {postal_codes_count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036c629-5b52-4e48-a6d2-b5875ff64358",
   "metadata": {},
   "source": [
    "Everything has been properly retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b888d8-e195-447c-8be7-f192af4f0254",
   "metadata": {},
   "source": [
    "## [4] Data Cleaning and Formatting\n",
    "\n",
    "Remove the noise from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ff672a-37b7-4ea6-a40d-7adb49a4bd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of unassigned postal codes removal\n",
      "Quebec City: Removed 60, final rows: 140\n",
      "Montreal: Removed 57, final rows: 123\n",
      "Ottawa: Removed 76, final rows: 84\n",
      "Toronto: No removals, final rows: 97\n",
      "Vancouver: Removed 5, final rows: 195\n",
      "Paris: No removals, final rows: 20\n",
      "Total\n",
      "Removed 198, final rows: 659\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store the count of removed rows for each city\n",
    "city_counts = {}\n",
    "\n",
    "# Calculate the initial number of rows for each city, including unassigned postal codes\n",
    "for city in citiesinfo_dic['city0']:\n",
    "    city_df = cities_df[cities_df['City'] == city]\n",
    "    unassigned_city_count = city_df[((city_df['Borough'].isna()) | (city_df['Borough'] == 'Not assigned') | (city_df['Borough'] == 'Unknown')) &\n",
    "    ((city_df['Neighborhood'].isna()) | (city_df['Neighborhood'] == 'Not assigned') | (city_df['Neighborhood'] == 'Unknown'))\n",
    "    ].shape[0]\n",
    "    final_city_count = city_df.shape[0] - unassigned_city_count\n",
    "    city_counts[city] = (unassigned_city_count, final_city_count)\n",
    "\n",
    "# Now perform the removal of unassigned postal codes for the entire DataFrame\n",
    "cities_df = cities_df[~(((cities_df['Borough'].isna()) |(cities_df['Borough'] == 'Not assigned') | (cities_df['Borough'] == 'Unknown')) & \n",
    "                        ((cities_df['Neighborhood'].isna()) |(cities_df['Neighborhood'] == 'Not assigned') | (cities_df['Neighborhood'] == 'Unknown')))]\n",
    "\n",
    "# Calculate total removed across all cities\n",
    "unassigned_cities_count = sum(unassigned_city_count[0] for unassigned_city_count in city_counts.values())\n",
    "final_cities_count = cities_df.shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary of unassigned postal codes removal\")\n",
    "for city, (unassigned_city_count, final_city_count) in city_counts.items():\n",
    "    if unassigned_city_count > 0:\n",
    "        print(f\"{city}: Removed {unassigned_city_count}, final rows: {final_city_count}\")\n",
    "    else:\n",
    "        print(f\"{city}: No removals, final rows: {final_city_count}\")\n",
    "print(\"Total\")\n",
    "if unassigned_cities_count > 0:\n",
    "    print(f\"Removed {unassigned_cities_count}, final rows: {final_cities_count}\")\n",
    "else:\n",
    "    print(f\"No unassigned postal codes were removed across all cities. The dataframe retains all {final_cities_count} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef23ac-9afa-4fa0-8386-3a853dd9faaf",
   "metadata": {},
   "source": [
    "Let's proceed to a visual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7b25959-8116-4e11-96db-3cc2b6ae8d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Postalcode</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>City</th>\n",
       "      <th>City1</th>\n",
       "      <th>City2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G1A</td>\n",
       "      <td>Quebec Provincial Government</td>\n",
       "      <td>Quebec Provincial Government</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec City, Quebec</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G2A</td>\n",
       "      <td>North Loretteville</td>\n",
       "      <td>North Loretteville</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec City, Quebec</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G3A</td>\n",
       "      <td>Saint-Augustin-de-Desmaures</td>\n",
       "      <td>Saint-Augustin-de-Desmaures</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec City, Quebec</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G4A</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>Clermont</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec City, Quebec</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G5A</td>\n",
       "      <td>La Malbaie</td>\n",
       "      <td>La Malbaie</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>Quebec City, Quebec</td>\n",
       "      <td>Quebec City, QC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Postalcode                       Borough                  Neighborhood  \\\n",
       "0        G1A  Quebec Provincial Government  Quebec Provincial Government   \n",
       "1        G2A            North Loretteville            North Loretteville   \n",
       "2        G3A   Saint-Augustin-de-Desmaures   Saint-Augustin-de-Desmaures   \n",
       "3        G4A                      Clermont                      Clermont   \n",
       "4        G5A                    La Malbaie                    La Malbaie   \n",
       "\n",
       "          City                City1            City2  \n",
       "0  Quebec City  Quebec City, Quebec  Quebec City, QC  \n",
       "1  Quebec City  Quebec City, Quebec  Quebec City, QC  \n",
       "2  Quebec City  Quebec City, Quebec  Quebec City, QC  \n",
       "3  Quebec City  Quebec City, Quebec  Quebec City, QC  \n",
       "4  Quebec City  Quebec City, Quebec  Quebec City, QC  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the index of the filtered DataFrame and display it\n",
    "cities_df.reset_index(drop=True, inplace=True)\n",
    "cities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d728d28-e859-4b9f-9ed5-e51a50807ce0",
   "metadata": {},
   "source": [
    "Upon visual inspection, we observed that the results are not flawless, as they include the following issues:\n",
    "- Neighborhood entries containing commas, embedded postal codes, parentheses, or missing spaces\n",
    "- Incomplete retrieval of borough and neighborhood names\n",
    "- Reversed borough and neighborhood names\n",
    "- Other similar inconsistencies\n",
    "\n",
    "However, since our geolocation analysis will primarily focus on postal codes, these issues won't significantly affect our process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47f496-3dcc-4f48-9e1a-2d83b8276946",
   "metadata": {},
   "source": [
    "## [5] Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3b56284-9e45-4e15-8a6a-9f3ecd261d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'wikipedia_df_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file with UTF-8 encoding\n",
    "cities_df.to_csv('wikipedia_df_output.csv', index=False, encoding='utf-8')\n",
    "print(\"DataFrame saved as 'wikipedia_df_output.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaa28ecf-bc81-47e2-93ce-b47ef1482c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the element with key \"key2\"\n",
    "del citiesinfo_dic[\"soup\"]\n",
    "# Save to JSON file\n",
    "with open(\"wikipedia_dic_output.json\", \"w\") as f:\n",
    "    json.dump(citiesinfo_dic, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50293ea7-6d04-4090-946a-55ae034b9710",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Neighborhoods | Canadian Rent Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfa724-e72d-4607-abe4-aeca0dcb0ea4",
   "metadata": {},
   "source": [
    "The Canada Mortgage and Housing Corporation is Canada's national housing agency. It is responsible for providing reliable housing market data and analysis. We will retrieve 2023 canadian median rent prices.\n",
    "\n",
    "Link: https://www.cmhc-schl.gc.ca/professionnels/marche-du-logement-donnees-et-recherche/donnees-sur-le-logement/tableaux-de-donnees/donnees-sur-le-marche-locatif/enquete-sur-les-logements-locatifs-centres-urbains-loyers-moyens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b28a7-a9b1-45e5-a125-9776296c74c7",
   "metadata": {},
   "source": [
    "## [1] Working environment set up\n",
    "\n",
    "Before starting, we need to install and import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90788583-e36e-41c3-90c2-0d295e2b033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: unidecode in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.8)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.26.1)\n",
      "Requirement already satisfied: Levenshtein==0.26.1 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-Levenshtein) (0.26.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.10.0)\n",
      "Requirement already satisfied: geocoder in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.38.1)\n",
      "Requirement already satisfied: click in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geocoder) (8.1.7)\n",
      "Requirement already satisfied: future in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geocoder) (1.0.0)\n",
      "Requirement already satisfied: ratelim in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: requests in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geocoder) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geocoder) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->geocoder) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ratelim->geocoder) (5.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->geocoder) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->geocoder) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->geocoder) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->geocoder) (2024.7.4)\n",
      "Requirement already satisfied: geopy in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\marin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from geopy) (2.0)\n",
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Data Storage and File Handling\n",
    "import json\n",
    "!pip install openpyxl\n",
    "\n",
    "# Data Manipulation and Processing\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "!pip install unidecode\n",
    "import unidecode\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Geolocation and Mapping\n",
    "!pip install geocoder\n",
    "import geocoder\n",
    "!pip install geopy\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682bb3b-3eb2-4de5-9cfc-5960ce064fdd",
   "metadata": {},
   "source": [
    "## [2] Data Collection\n",
    "\n",
    "Before starting, we need to open the venue dataframe and the geolocation dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fee4b6c-c431-4198-844b-f4f63703b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from CSV file\n",
    "cities_df = pd.read_csv('venue_df_output.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cede5149-b1d6-4f69-be5d-5d3b244fed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from JSON file\n",
    "with open(\"geolocation_dic_output.json\", \"r\") as f:\n",
    "    citiesinfo_dic = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f124b7-e9ed-45ee-ae8c-11d551a0940f",
   "metadata": {},
   "source": [
    "Then, to retrieve the Canadian housing data, we will investigate the zip folder provided by the Canadian statistics department to how the tabs are formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bde550-6716-47ff-8345-82b5a968738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file to see its structure and content\n",
    "cmhc_path = r'C:\\Users\\marin\\OneDrive\\Documents\\GITHUB\\urban-rental-market-survey-data-average-rents-urban-centres-2023-en.xlsx'\n",
    "\n",
    "# Load the Excel file to get all sheet names\n",
    "excel_file = pd.ExcelFile(cmhc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4d7edb-641c-4629-ae3f-2e213f2b808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: CSD\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Subdivision for Centres 10,000+\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Subdivision for Centres 10,000+', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Census Subdivision', 'Dwelling Type', 'Bachelor', nan, '1 Bedroom', nan, '2 Bedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Testing row 4: ['Nfld.Lab.', \"St. John's\", 'Holyrood (T)', 'Row', '--', nan, '--', nan, '--', nan, '--', nan, '--', nan]\n",
      "Testing row 5: ['Nfld.Lab.', \"St. John's\", 'Holyrood (T)', 'Apt & Other', '--', nan, '--', nan, '--', nan, '--', nan, '--', nan]\n",
      "Testing row 6: ['Nfld.Lab.', \"St. John's\", 'Holyrood (T)', 'Total', '--', nan, '--', nan, '--', nan, '--', nan, '--', nan]\n",
      "Testing row 7: ['Nfld.Lab.', \"St. John's\", 'Conception Bay South (T)', 'Row', '--', \"'\", '**', \"'\", '$1017', 'd', '--', \"'\", '$1009', 'd']\n",
      "Valid header found at row 7\n",
      "\n",
      "\n",
      "Sheet Name: Neighbourhood\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Neighbourhood for Census Metropolitan Areas\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Neighbourhood for Census Metropolitan Areas', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Zone', 'Neighbourhood', 'Dwelling\\nType', 'Bachelor', nan, '1\\nBedroom', nan, '2\\nBedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Testing row 4: ['Nfld.Lab.', \"St. John's\", \"St. John's East\", \"St. John's East\", 'Row', '**', \"'\", '**', \"'\", '**', \"'\", '**', \"'\", '$1352', 'c']\n",
      "Valid header found at row 4\n",
      "\n",
      "\n",
      "Sheet Name: CT\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Tract for Census Metropolitan Areas\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Tract for Census Metropolitan Areas', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Census\\nTract', 'Dwelling\\nType', 'Bachelor', nan, '1 Bedroom', nan, '2 Bedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Testing row 4: ['Nfld.Lab.', \"St. John's\", '0001.00', 'Row', '--', nan, '--', nan, '--', nan, '--', nan, '--', nan]\n",
      "Testing row 5: ['Nfld.Lab.', \"St. John's\", '0001.00', 'Apt & Other', '--', \"'\", '**', \"'\", '--', \"'\", '--', \"'\", '**', \"'\"]\n",
      "Valid header found at row 5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find the first valid header row\n",
    "def find_valid_header_test1(df):\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"Testing row {i}: {row.tolist()}\")                               # Print the current row being tested\n",
    "        if all(isinstance(val, str) and val.strip() != \"\" for val in row):      # Check if the row contains valid column names (non-empty strings)\n",
    "            print(f\"Valid header found at row {i}\")                             # Print when a valid header is found\n",
    "            return i, row.tolist()                                              # Return the row index and the column names\n",
    "    return None, None                                                           # Return None if no valid header is found\n",
    "\n",
    "# Iterate the function over each sheet\n",
    "for sheet in excel_file.sheet_names:\n",
    "    df = pd.read_excel(excel_file, sheet, header = None)                        # Load without headers\n",
    "    print(f\"Sheet Name: {sheet}\")\n",
    "    sheet_title = df.iloc[0, 0] if not pd.isnull(df.iloc[0, 0]) else 'No title' # The sheet title is assumed to be in the first row\n",
    "    print(f\"Sheet Title: {sheet_title}\")\n",
    "    header_index, columns = find_valid_header_test1(df)                               # Try to find a valid header starting from row 4\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca021f34-c982-4568-9c14-cf3e500e2017",
   "metadata": {},
   "source": [
    "We ran an automated header checker to evaluate each row of the worksheets and identify the correct header row. However, we noticed that the process needs some refinement. The checker actually selects rows containing additional information, which aren’t the official headers, but rather supplementary data. A clearer definition of what qualifies as a header is necessary to ensure accurate detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2440ff30-10b7-4ef7-bd14-84cbf89217ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: CSD\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Subdivision for Centres 10,000+\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Subdivision for Centres 10,000+', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Census Subdivision', 'Dwelling Type', 'Bachelor', nan, '1 Bedroom', nan, '2 Bedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Valid header found at row 3\n",
      "\n",
      "\n",
      "Sheet Name: Neighbourhood\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Neighbourhood for Census Metropolitan Areas\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Neighbourhood for Census Metropolitan Areas', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Zone', 'Neighbourhood', 'Dwelling\\nType', 'Bachelor', nan, '1\\nBedroom', nan, '2\\nBedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Valid header found at row 3\n",
      "\n",
      "\n",
      "Sheet Name: CT\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Tract for Census Metropolitan Areas\n",
      "Testing row 0: ['Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Census Tract for Census Metropolitan Areas', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 1: ['October 2023', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 2: [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Testing row 3: ['Province', 'Centre', 'Census\\nTract', 'Dwelling\\nType', 'Bachelor', nan, '1 Bedroom', nan, '2 Bedroom', nan, '3 Bedroom\\n+', nan, 'Total', nan]\n",
      "Valid header found at row 3\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find the first valid header row\n",
    "def find_valid_header_test2(df):\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"Testing row {i}: {row.tolist()}\")                                   # Print the current row being tested\n",
    "        valid_strings = [isinstance(val, str) and val.strip() != \"\" for val in row] # Create a mask of whether each value is a valid string\n",
    "        consecutive_count = 0\n",
    "        for is_valid in valid_strings:                                              \n",
    "            if is_valid:\n",
    "                consecutive_count += 1\n",
    "                if consecutive_count >= 3:                                          # If we find 3 consecutive valid strings, this is the header row\n",
    "                    print(f\"Valid header found at row {i}\")                         # Print when a valid header is found\n",
    "                    return i, [val for val in row if pd.notna(val)]                 # Return the row index and the column names (removing NaN)\n",
    "            else:\n",
    "                consecutive_count = 0                                               # Reset the counter if interrupted by NaN or invalid string    \n",
    "    return None, None                                                               # Return None if no valid header is found\n",
    "\n",
    "# Iterate the function over each sheet\n",
    "for sheet in excel_file.sheet_names:\n",
    "    df = pd.read_excel(excel_file, sheet, header = None)                            # Load without headers\n",
    "    print(f\"Sheet Name: {sheet}\")\n",
    "    sheet_title = df.iloc[0, 0] if not pd.isnull(df.iloc[0, 0]) else 'No title'     # The sheet title is assumed to be in the first row\n",
    "    print(f\"Sheet Title: {sheet_title}\")\n",
    "    header_index, columns = find_valid_header_test2(df)                                   # Try to find a valid header starting from row 4\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1a6bf-ee39-4b06-b573-4602408981f9",
   "metadata": {},
   "source": [
    "Great, it worked! we can now focus on finding the correct worksheet with the neighborhood cut to review its columns fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3d2f84-95d2-4a63-ac49-7b9a047598af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Name: Neighbourhood\n",
      "Sheet Title: Private Row (Townhouse) and Apartment Average Rent by Bedroom Type and Neighbourhood for Census Metropolitan Areas\n",
      "Header Index: 3\n",
      "Columns: ['Province', 'Centre', 'Zone', 'Neighbourhood', 'Dwelling Type', 'Bachelor', '1 Bedroom', '2 Bedroom', '3 Bedroom +', 'Total']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to find the first valid header row\n",
    "def find_valid_header(df):\n",
    "    for i, row in df.iterrows():\n",
    "        valid_strings = [isinstance(val, str) and val.strip() != \"\" for val in row]\n",
    "        consecutive_count = 0\n",
    "        for is_valid in valid_strings:\n",
    "            if is_valid:\n",
    "                consecutive_count += 1\n",
    "                if consecutive_count >= 3:\n",
    "                    return i, [val for val in row if pd.notna(val)]\n",
    "            else:\n",
    "                consecutive_count = 0                                                  \n",
    "    return None, None\n",
    "\n",
    "# Dictionary to store columns of each sheet\n",
    "sheetsdetails_dic = {}\n",
    "\n",
    "# Build a function to remove the '\\n' from the columns names\n",
    "def clean_columns(column_list):\n",
    "    return [col.replace('\\n', ' ') if isinstance(col, str) else col for col in column_list]\n",
    "\n",
    "# Iterate over each sheet to search for valid columns\n",
    "for sheet in excel_file.sheet_names:\n",
    "    df = pd.read_excel(excel_file, sheet_name = sheet, header = None)\n",
    "    sheet_title = df.iloc[0, 0] if not pd.isnull(df.iloc[0, 0]) else 'No title'\n",
    "    header_index, columns = find_valid_header(df) \n",
    "    # When valid columns are found, update the dictionary\n",
    "    if columns:\n",
    "        cleaned_columns = clean_columns(columns)\n",
    "        sheetsdetails_dic[sheet] = {'sheet_title': sheet_title, 'header_index': header_index, 'columns': columns, 'cleaned_columns': cleaned_columns}\n",
    "\n",
    "# Print the found columns for each sheet\n",
    "for sheet_name, sheet_info in sheetsdetails_dic.items():\n",
    "    neighborhood_sheet_name = sheet_name\n",
    "    if \"Neighbourhood\" in sheet_info['columns']: # Quartier means neighborhood in French\n",
    "        print(f\"Sheet Name: {sheet_name}\")\n",
    "        print(f\"Sheet Title: {sheet_info['sheet_title']}\")\n",
    "        print(f\"Header Index: {sheet_info['header_index']}\")\n",
    "        print(f\"Columns: {sheet_info['cleaned_columns']}\")\n",
    "        print(\"\\n\")\n",
    "        break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e791eaac-7e5c-45a1-ae5e-e82dd61f301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3915, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Dwelling\\nType</th>\n",
       "      <th>Bachelor</th>\n",
       "      <th>1\\nBedroom</th>\n",
       "      <th>2\\nBedroom</th>\n",
       "      <th>3 Bedroom\\n+</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nfld.Lab.</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>Row</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>$1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nfld.Lab.</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>Apt &amp; Other</td>\n",
       "      <td>$695</td>\n",
       "      <td>$987</td>\n",
       "      <td>$1264</td>\n",
       "      <td>$998</td>\n",
       "      <td>$1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nfld.Lab.</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>Total</td>\n",
       "      <td>$695</td>\n",
       "      <td>$984</td>\n",
       "      <td>$1262</td>\n",
       "      <td>$1238</td>\n",
       "      <td>$1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nfld.Lab.</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>Total</td>\n",
       "      <td>Row</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>**</td>\n",
       "      <td>$1352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nfld.Lab.</td>\n",
       "      <td>St. John's</td>\n",
       "      <td>St. John's East</td>\n",
       "      <td>Total</td>\n",
       "      <td>Apt &amp;\\nOther</td>\n",
       "      <td>$695</td>\n",
       "      <td>$987</td>\n",
       "      <td>$1264</td>\n",
       "      <td>$998</td>\n",
       "      <td>$1117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province      Centre             Zone    Neighbourhood Dwelling\\nType  \\\n",
       "0  Nfld.Lab.  St. John's  St. John's East  St. John's East            Row   \n",
       "1  Nfld.Lab.  St. John's  St. John's East  St. John's East    Apt & Other   \n",
       "2  Nfld.Lab.  St. John's  St. John's East  St. John's East          Total   \n",
       "3  Nfld.Lab.  St. John's  St. John's East            Total            Row   \n",
       "4  Nfld.Lab.  St. John's  St. John's East            Total   Apt &\\nOther   \n",
       "\n",
       "  Bachelor 1\\nBedroom 2\\nBedroom 3 Bedroom\\n+  Total  \n",
       "0       **         **         **           **  $1352  \n",
       "1     $695       $987      $1264         $998  $1117  \n",
       "2     $695       $984      $1262        $1238  $1123  \n",
       "3       **         **         **           **  $1352  \n",
       "4     $695       $987      $1264         $998  $1117  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the correct sheet using the header index to build the DataFrame\n",
    "df = pd.read_excel(excel_file, sheet_name=neighborhood_sheet_name, header=sheetsdetails_dic[neighborhood_sheet_name]['header_index'])\n",
    "\n",
    "# Select only the columns from sheet_info['columns']\n",
    "selected_columns = sheetsdetails_dic[neighborhood_sheet_name]['columns']\n",
    "cmhc_df = df[selected_columns]\n",
    "cmhc_df.dropna(inplace=True)\n",
    "print(cmhc_df.shape)\n",
    "cmhc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1686fe-03fe-4551-b492-b8eff9d7dcae",
   "metadata": {},
   "source": [
    "## [3] Data Cleaning and Formatting\n",
    "\n",
    "To be able to use the data from the canadian housing institude cmhc, we will need to format their summary table into pure data. We will have to remove the rows without data and rows with totals. Then we will need to filter only on the canadian cities within our exercise. Though we are facing another language barrier here as the french files includes french naming conventions and french accents. Hence to be able to compare both data, we will have to normalize the data by removing accents and converting to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e84f77d1-3e5f-4463-83d4-e5207446736c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved cities from wiki_dic in the dataframe: ['Montreal', 'Quebec City', 'Ottawa', 'Toronto', 'Vancouver']\n",
      "Missing cities from wiki_dic that were not found in the dataframe: ['Paris']\n",
      "(337, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province</th>\n",
       "      <th>Centre</th>\n",
       "      <th>Zone</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Dwelling Type</th>\n",
       "      <th>Bachelor</th>\n",
       "      <th>1 Bedroom</th>\n",
       "      <th>2 Bedroom</th>\n",
       "      <th>3 Bedroom +</th>\n",
       "      <th>Total</th>\n",
       "      <th>Centre_normalized</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Que</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>Downtown Montréal/Îles-des-Soeurs</td>\n",
       "      <td>Ville-Marie</td>\n",
       "      <td>Total</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>montreal</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Que</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>Downtown Montréal/Îles-des-Soeurs</td>\n",
       "      <td>Île-des-Soeurs</td>\n",
       "      <td>Total</td>\n",
       "      <td>927.0</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>montreal</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Que</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>Sud-Ouest/Verdun</td>\n",
       "      <td>Verdun</td>\n",
       "      <td>Total</td>\n",
       "      <td>800.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>1394.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>montreal</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Que</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>Sud-Ouest/Verdun</td>\n",
       "      <td>South West</td>\n",
       "      <td>Total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974.0</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>montreal</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Que</td>\n",
       "      <td>Montréal</td>\n",
       "      <td>LaSalle</td>\n",
       "      <td>LaSalle</td>\n",
       "      <td>Total</td>\n",
       "      <td>750.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>montreal</td>\n",
       "      <td>Montreal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province    Centre                               Zone   Neighbourhood  \\\n",
       "368      Que  Montréal  Downtown Montréal/Îles-des-Soeurs     Ville-Marie   \n",
       "371      Que  Montréal  Downtown Montréal/Îles-des-Soeurs  Île-des-Soeurs   \n",
       "377      Que  Montréal                   Sud-Ouest/Verdun          Verdun   \n",
       "380      Que  Montréal                   Sud-Ouest/Verdun      South West   \n",
       "386      Que  Montréal                            LaSalle         LaSalle   \n",
       "\n",
       "    Dwelling Type  Bachelor  1 Bedroom  2 Bedroom  3 Bedroom +   Total  \\\n",
       "368         Total    1146.0     1429.0     2012.0       2072.0  1527.0   \n",
       "371         Total     927.0     1139.0     1357.0       1419.0  1226.0   \n",
       "377         Total     800.0      952.0      938.0       1394.0  1028.0   \n",
       "380         Total       NaN      974.0     1246.0          NaN  1154.0   \n",
       "386         Total     750.0      924.0     1199.0       1596.0  1273.0   \n",
       "\n",
       "    Centre_normalized      City  \n",
       "368          montreal  Montreal  \n",
       "371          montreal  Montreal  \n",
       "377          montreal  Montreal  \n",
       "380          montreal  Montreal  \n",
       "386          montreal  Montreal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the column names\n",
    "cmhc_df.columns = cmhc_df.columns.str.replace('\\n', ' ')\n",
    "\n",
    "# Remove the extra rows\n",
    "cmhc_df = cmhc_df[cmhc_df['Dwelling Type'] == 'Total']\n",
    "cmhc_df = cmhc_df[~cmhc_df['Neighbourhood'].str.contains('Total', case=False, na=False)]\n",
    "\n",
    "# Remove the empty data rows\n",
    "rent_columns = cmhc_df.columns[-5:-1]  # Adjust the range to exclude the last column named Total\n",
    "cmhc_df[rent_columns] = cmhc_df[rent_columns].replace(r'[\\$,]', '', regex=True).apply(pd.to_numeric, errors = 'coerce')\n",
    "cmhc_df = cmhc_df.dropna(subset = rent_columns, how = 'all')\n",
    "\n",
    "# Build a function to normalise city names for comparison (removing accents, 'city', etc.)\n",
    "def normalize_city_name(city):\n",
    "    city = unicodedata.normalize('NFKD', city).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    city = re.sub(r'\\b(city|ville)\\b', '', city, flags=re.IGNORECASE).strip()\n",
    "    city = re.sub(r'[^\\w\\s]', '', city).lower()\n",
    "    return city\n",
    "\n",
    "citiesinfo_original_list = [city for city in citiesinfo_dic['city0']]\n",
    "citiesinfo_normalized_list = [normalize_city_name(city) for city in citiesinfo_original_list]\n",
    "cmhc_df['Centre_normalized'] = cmhc_df['Centre'].apply(normalize_city_name)\n",
    "\n",
    "# Get the list of retrieved cities with their normalized name\n",
    "citiesretrieved_normalized_list = cmhc_df[cmhc_df['Centre_normalized'].isin(citiesinfo_normalized_list)]['Centre_normalized'].unique().tolist()\n",
    "\n",
    "# Get the list of retrieved cities with their original name according to our dictionary formatting\n",
    "citiesretrieved_original_list = []\n",
    "for normalized_city in citiesretrieved_normalized_list:\n",
    "    if normalized_city in citiesinfo_normalized_list:\n",
    "        # Find the index of the normalized city and retrieve the original city name from the original list\n",
    "        original_city = citiesinfo_original_list[citiesinfo_normalized_list.index(normalized_city)]\n",
    "        citiesretrieved_original_list.append(original_city)\n",
    "        \n",
    "# Get the list of missing cities with their original name according to our dictionary formatting\n",
    "citiesmissing_original_list = set(citiesinfo_original_list) - set(citiesretrieved_original_list)\n",
    "citiesmissing_original_list = list(citiesmissing_original_list)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Retrieved cities from wiki_dic in the dataframe: {citiesretrieved_original_list}\")\n",
    "print(f\"Missing cities from wiki_dic that were not found in the dataframe: {citiesmissing_original_list}\")\n",
    "\n",
    "# Final list of cities to investigate in the cmhc file\n",
    "canadiancity_list = cmhc_df[cmhc_df['Centre_normalized'].isin(citiesinfo_normalized_list)]['Centre'].unique().tolist()\n",
    "cmhc_df = cmhc_df[cmhc_df['Centre'].isin(canadiancity_list)]\n",
    "\n",
    "# Update the city name with the one from our citiesinfo dictionary\n",
    "normalized_to_original_dic = dict(zip(citiesinfo_normalized_list, citiesinfo_original_list))\n",
    "cmhc_df['City'] = cmhc_df['Centre_normalized'].map(normalized_to_original_dic).fillna(cmhc_df['Centre'])\n",
    "\n",
    "# Display the final filtered dataframe\n",
    "print(cmhc_df.shape)\n",
    "cmhc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55348-d22b-462e-971e-56912901a554",
   "metadata": {},
   "source": [
    "Paris is obviously missing from the matching cities as we are working on the canadian file.\n",
    "\n",
    "We aim to identify the most effective method for matching neighborhoods in the CMHC dataset with those in the cities_df dataframe. To do this, we will evaluate three techniques: direct matching, fuzzy matching, and geolocation matching. By comparing the accuracy of each method, we will determine which approach provides the highest number of successful matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe11290-2a90-4da0-8f2d-a17ebf36b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to normalize the neighborhood names: Remove accents, convert to lowercase, strip spaces\n",
    "def normalize_neighborhood(name):\n",
    "    if pd.notna(name):\n",
    "        name = unidecode.unidecode(name).lower().strip()\n",
    "        return name\n",
    "    return name\n",
    "\n",
    "# Apply normalization\n",
    "cmhc_df['Neigh_normalized'] = cmhc_df['Neighbourhood'].apply(normalize_neighborhood)\n",
    "cities_df['Neigh_normalized'] = cities_df['Neighborhood'].apply(normalize_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af517f-1731-480a-a314-b2f60783dfb6",
   "metadata": {},
   "source": [
    "**First Matching Method: Direct Matching**\n",
    "\n",
    "This method compares neighborhood names exactly as they are written in both datasets. It relies on the assumption that the names in both sources are spelled identically, including spaces, punctuation, and capitalization. While simple and efficient, this method can miss matches due to minor variations like accents, abbreviations, or typos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ee6dbf-d6eb-4879-bb6f-4795edeb5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_match(first_neigh, first_city, second_neigh, second_city):\n",
    "    if city != second_city:\n",
    "        return False\n",
    "    second_parts = [part.strip() for part in second_neigh.split(',')]  # Split second_parts by commas\n",
    "    return any(part in first_neigh for part in second_parts)  # Return True if any part matches first_neigh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367212c-a286-4f8f-b884-d6941c83cf75",
   "metadata": {},
   "source": [
    "**Second Matching Method: Fuzzy Matching**\n",
    "\n",
    "This method uses algorithms to compare the similarity of neighborhood names, allowing for partial matches even when names aren't identical. It applies techniques such as token sorting and Levenshtein distance to find close matches based on the degree of similarity between strings. This method is more flexible than direct matching but can occasionally result in false positives or less relevant matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2491c08b-6712-45a7-9101-8d739749a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare city neighborhood lists for fuzzy matching\n",
    "cities_neigh_dict = {}\n",
    "# Group the DataFrame by 'City' and then split and process neighborhoods within each city\n",
    "for city, group in cities_df.groupby('City'):\n",
    "    neigh_list = [part.strip() for neigh in group['Neigh_normalized'].unique() for part in neigh.split(',')]\n",
    "    cities_neigh_dict[city] = neigh_list\n",
    "\n",
    "def fuzzy_match(first_neigh, first_city, threshold=70):\n",
    "    best_match = None\n",
    "    highest_score = 0\n",
    "    match, score = process.extractOne(first_neigh, cities_neigh_dict[first_city], scorer=fuzz.token_sort_ratio)\n",
    "    if score >= threshold:\n",
    "        best_match = match\n",
    "    return best_match if best_match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f41a0d35-5f20-4e2e-961d-38fc089a0bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a cache to store geolocation results\n",
    "geo_cache = {}\n",
    "\n",
    "def geoloc_match(location, city, max_retries=5, max_distance_km=2):\n",
    "    # Adapt the city name to the geocoder format\n",
    "    city = citiesinfo_dic['city1'][citiesinfo_dic['city0'].index(city)]\n",
    "    # Check if the location and city are already in the cache\n",
    "    if (location, city) in geo_cache:\n",
    "        # Check if a postal code match was successful\n",
    "        return geo_cache[(location, city)]['postalcode'] is not None\n",
    "\n",
    "    retries = 0\n",
    "    lati_long_coords = None\n",
    "    \n",
    "    # Try to retrieve the coordinates with retries\n",
    "    while lati_long_coords is None and retries < max_retries:\n",
    "        g = geocoder.arcgis('{}, {}'.format(location, city))\n",
    "        lati_long_coords = g.latlng\n",
    "        if lati_long_coords is None:\n",
    "            retries += 1\n",
    "    \n",
    "    # If geolocation fails after retries, cache it as None and return False\n",
    "    if lati_long_coords is None:\n",
    "        geo_cache[(location, city)] = {'coordinates': None, 'postalcode': None}\n",
    "        return False\n",
    "    \n",
    "    # If geolocation is successful, check proximity with citysource_df\n",
    "    lat, lon = lati_long_coords\n",
    "    min_distance = float('inf')\n",
    "    closest_postalcode = None\n",
    "    \n",
    "    for _, cities_row in cities_df.iterrows():\n",
    "        cities_coords = (cities_row['Latitude'], cities_row['Longitude'])\n",
    "        neighborhood_coords = (lat, lon)\n",
    "        distance = geodesic(cities_coords, neighborhood_coords).kilometers\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_postalcode = cities_row['Postalcode']\n",
    "    \n",
    "    # If the minimum distance is greater than max_distance_km, consider it a failed match\n",
    "    if min_distance > max_distance_km:\n",
    "        closest_postalcode = None\n",
    "    \n",
    "    # Cache the result (whether or not a postal code was matched)\n",
    "    geo_cache[(location, city)] = {'coordinates': lati_long_coords, 'postalcode': closest_postalcode}\n",
    "\n",
    "    # Return True if there was a successful match, otherwise return False\n",
    "    return closest_postalcode is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f09d8-7639-4b04-abde-0f2b8d607086",
   "metadata": {},
   "source": [
    "**Third Matching Method: Geolocation Matching**\n",
    "\n",
    "This method works by converting neighborhood names into latitude and longitude coordinates and finding the closest match based on geographical proximity. This method uses the actual physical locations of neighborhoods to determine matches, which is useful when names are inconsistent or ambiguous. However, it depends on accurate geolocation data and may take longer to process due to external API requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac65d79-7806-4b34-8845-abe81a2758a7",
   "metadata": {},
   "source": [
    "**Testing the Matching Methods**\n",
    "\n",
    "Let's test our 3 methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971b9392-d71e-4185-8388-e45dc7b3339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total neighborhoods to match: 337\n",
      "Number of direct matches: 40 (11.87%)\n",
      "Number of fuzzy matches: 157 (46.59%)\n",
      "Number of geolocation matches: 280 (83.09%)\n",
      "Best matching method: Geolocation Matching\n"
     ]
    }
   ],
   "source": [
    "# Initialize count for matched neighborhoods using both methods\n",
    "direct_match_count = 0\n",
    "fuzzy_match_count = 0\n",
    "geoloc_match_count = 0\n",
    "cmhc_totalcount = len(cmhc_df)  # Total number of neighborhoods in cmhc_df\n",
    "\n",
    "# Iterate through cmhc_df and check for matches using each method\n",
    "for _, cmhc_row in cmhc_df.iterrows():\n",
    "\n",
    "    # Direct match search\n",
    "    for _, cities_row in cities_df.iterrows():\n",
    "        if direct_match(cmhc_row['Neigh_normalized'], cmhc_row['City'], cities_row['Neigh_normalized'], cities_row['City']):\n",
    "            direct_match_count += 1\n",
    "            break  # Stop after the first direct match for each cmhc_df row\n",
    "    \n",
    "    # Fuzzy match search\n",
    "    if fuzzy_match(cmhc_row['Neigh_normalized'], cmhc_row['City']):\n",
    "        fuzzy_match_count += 1\n",
    "\n",
    "    # Geolocation match search\n",
    "    if geoloc_match(cmhc_row['Neigh_normalized'], cmhc_row['City']):\n",
    "        geoloc_match_count += 1\n",
    "\n",
    "# Calculate total matches and percentages\n",
    "direct_match_total = direct_match_count\n",
    "fuzzy_match_total = fuzzy_match_count\n",
    "geoloc_match_total = geoloc_match_count\n",
    "\n",
    "if cmhc_totalcount > 0:\n",
    "    direct_match_percentage = (direct_match_total / cmhc_totalcount) * 100\n",
    "    fuzzy_match_percentage = (fuzzy_match_total / cmhc_totalcount) * 100\n",
    "    geoloc_match_percentage = (geoloc_match_total / cmhc_totalcount) * 100\n",
    "else:\n",
    "    direct_match_percentage = 0\n",
    "    fuzzy_match_percentage = 0\n",
    "    geoloc_match_percentage = 0\n",
    "\n",
    "# Determine the best matching method\n",
    "if direct_match_total >= fuzzy_match_total and direct_match_total >= geoloc_match_total:\n",
    "    best_method = \"Direct Matching\"\n",
    "elif fuzzy_match_total >= direct_match_total and fuzzy_match_total >= geoloc_match_total:\n",
    "    best_method = \"Fuzzy Matching\"\n",
    "else:\n",
    "    best_method = \"Geolocation Matching\"\n",
    "\n",
    "# Output the results\n",
    "print(f\"Total neighborhoods to match: {cmhc_totalcount}\")\n",
    "print(f\"Number of direct matches: {direct_match_total} ({direct_match_percentage:.2f}%)\")\n",
    "print(f\"Number of fuzzy matches: {fuzzy_match_total} ({fuzzy_match_percentage:.2f}%)\")\n",
    "print(f\"Number of geolocation matches: {geoloc_match_total} ({geoloc_match_percentage:.2f}%)\")\n",
    "print(f\"Best matching method: {best_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5524051-addf-48ff-948e-cf454f7bd8e5",
   "metadata": {},
   "source": [
    "The geolocation method is the one with the best matching score. Let's apply it to connect our cmhc data to the cities_df postal coldes. To maximise our chances of connecting our neighborhoods together, instead of looking for the postal code that is the closest to our geolocation, we will list all the postal codes in a radius of 2km respective to our location in the cmhc file. Each of them will be impact by the rent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b478d5ca-0f64-42b5-8e33-4dd909833691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to geolocate each neighborhood in cmhc_df\n",
    "geo_cache = {}\n",
    "\n",
    "def get_neigh_latilong(location, city, max_retries=5):\n",
    "    city_full = citiesinfo_dic['city1'][citiesinfo_dic['city0'].index(city)]\n",
    "    if (location, city_full) in geo_cache:\n",
    "        return geo_cache[(location, city_full)]\n",
    "    retries = 0\n",
    "    lati_long_coords = None\n",
    "    while lati_long_coords is None and retries < max_retries:\n",
    "        g = geocoder.arcgis('{}, {}'.format(location, city_full))\n",
    "        lati_long_coords = g.latlng\n",
    "        if lati_long_coords is None:\n",
    "            retries += 1\n",
    "    if lati_long_coords is None:\n",
    "        lati_long_coords = [None, None]  # Set as None if the geolocation fails\n",
    "    geo_cache[(location, city_full)] = lati_long_coords\n",
    "    return lati_long_coords\n",
    "\n",
    "# Create a function to calculate distance and find the closest match\n",
    "def find_postalcodes(lat, lon, city, max_distance_km):\n",
    "    nearby_postalcodes = []\n",
    "    city_rows_df = cities_df[cities_df['City'] == city]\n",
    "    for _, city_row in city_rows_df.iterrows():\n",
    "        city_coords = (city_row['Latitude'], city_row['Longitude'])\n",
    "        neighborhood_coords = (lat, lon)\n",
    "        distance = geodesic(city_coords, neighborhood_coords).kilometers\n",
    "        if distance <= max_distance_km:\n",
    "            nearby_postalcodes.append(city_row['Postalcode'])\n",
    "    return nearby_postalcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ea8dbaf-cc79-4733-837c-19e9401849dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified columns\n",
    "canadianrentN_df = cmhc_df[['City', 'Neighbourhood', 'Bachelor', '1 Bedroom', '2 Bedroom', '3 Bedroom +']]\n",
    "canadianrentB_df = cmhc_df[['City', 'Zone', 'Bachelor', '1 Bedroom', '2 Bedroom', '3 Bedroom +']]\n",
    "\n",
    "# Rename the columns according to the number of bedrooms\n",
    "rent_columns = ['Median Rent Studio', 'Median Rent 1 Bedroom', 'Median Rent 2 Bedrooms', 'Median Rent 3 Bedrooms']\n",
    "canadianrentN_df.columns = ['City','Neighborhood'] + rent_columns\n",
    "canadianrentB_df.columns = ['City','Borough'] + rent_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1833b699-c65f-46b8-932b-a6f178f5d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Postal_Code</th>\n",
       "      <th>Median Rent Studio</th>\n",
       "      <th>Median Rent 1 Bedroom</th>\n",
       "      <th>Median Rent 2 Bedrooms</th>\n",
       "      <th>Median Rent 3 Bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3A</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H5A</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3B</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H5B</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3C</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Postal_Code  Median Rent Studio  Median Rent 1 Bedroom  \\\n",
       "0  Montreal         H3A              1146.0                 1429.0   \n",
       "1  Montreal         H5A              1146.0                 1429.0   \n",
       "2  Montreal         H3B              1146.0                 1429.0   \n",
       "3  Montreal         H5B              1146.0                 1429.0   \n",
       "4  Montreal         H3C              1146.0                 1429.0   \n",
       "\n",
       "   Median Rent 2 Bedrooms  Median Rent 3 Bedrooms  \n",
       "0                  2012.0                  2072.0  \n",
       "1                  2012.0                  2072.0  \n",
       "2                  2012.0                  2072.0  \n",
       "3                  2012.0                  2072.0  \n",
       "4                  2012.0                  2072.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply geolocation to each neighborhood and find the postal codes near enough the geolocation\n",
    "canadianrentN_df['LatLong'] = canadianrentN_df.apply(lambda row: get_neigh_latilong(row['Neighborhood'], row['City']), axis=1)\n",
    "canadianrentN_df[['Latitude', 'Longitude']] = pd.DataFrame(canadianrentN_df['LatLong'].tolist(), index = canadianrentN_df.index)\n",
    "\n",
    "# Find the postal codes within less than 2 kilometers of the cmch neighborhoods geolocation\n",
    "canadianrentN_df = canadianrentN_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "canadianrentN_df['Postal_Code'] = canadianrentN_df.apply(lambda row: find_postalcodes(row['Latitude'], row['Longitude'], row['City'], max_distance_km=2), axis=1)\n",
    "\n",
    "# Filter out rows without nearby postal codes, expand lists of postal codes into separate rows\n",
    "canadianrentN_df = canadianrentN_df.dropna(subset=['Postal_Code'])\n",
    "canadianrentN_df['Postal_Code'] = canadianrentN_df['Postal_Code'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "canadianrentN_df = canadianrentN_df.explode('Postal_Code').reset_index(drop=True)\n",
    "\n",
    "# Keep only 'City', 'Postal_Code', and rent columns to finalize the dataframe\n",
    "canadianrentN_df = canadianrentN_df[['City', 'Postal_Code'] + rent_columns]\n",
    "print(canadianrentN_df.shape)\n",
    "canadianrentN_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd632409-3ab6-4a2c-8336-550e700d3864",
   "metadata": {},
   "source": [
    "To make sure we won't be missing a significant amount of median rent data in our main dataframe, we will also compute median rents based on boroughs from the cmhc source and match them with the corresponding boroughs in our dataset to fill in the missing values after the neighborhoods matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca43da2-e457-4475-966a-9a4ad54601b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6614, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Postal_Code</th>\n",
       "      <th>Median Rent Studio</th>\n",
       "      <th>Median Rent 1 Bedroom</th>\n",
       "      <th>Median Rent 2 Bedrooms</th>\n",
       "      <th>Median Rent 3 Bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H5A</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3B</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3C</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H4C</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Montreal</td>\n",
       "      <td>H3E</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2072.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City Postal_Code  Median Rent Studio  Median Rent 1 Bedroom  \\\n",
       "0  Montreal         H5A              1146.0                 1429.0   \n",
       "1  Montreal         H3B              1146.0                 1429.0   \n",
       "2  Montreal         H3C              1146.0                 1429.0   \n",
       "3  Montreal         H4C              1146.0                 1429.0   \n",
       "4  Montreal         H3E              1146.0                 1429.0   \n",
       "\n",
       "   Median Rent 2 Bedrooms  Median Rent 3 Bedrooms  \n",
       "0                  2012.0                  2072.0  \n",
       "1                  2012.0                  2072.0  \n",
       "2                  2012.0                  2072.0  \n",
       "3                  2012.0                  2072.0  \n",
       "4                  2012.0                  2072.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply geolocation to each borough and find the postal codes near enough the geolocation\n",
    "canadianrentB_df['LatLong'] = canadianrentB_df.apply(lambda row: get_neigh_latilong(row['Borough'], row['City']), axis=1)\n",
    "canadianrentB_df[['Latitude', 'Longitude']] = pd.DataFrame(canadianrentB_df['LatLong'].tolist(), index=canadianrentB_df.index)\n",
    "\n",
    "# Find the postal codes within less than 5 kilometers of the cmch borough geolocation\n",
    "canadianrentB_df = canadianrentB_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "canadianrentB_df['Postal_Code'] = canadianrentB_df.apply(lambda row: find_postalcodes(row['Latitude'], row['Longitude'], row['City'], max_distance_km=5), axis=1)\n",
    "\n",
    "# Filter out rows without nearby postal codes, expand lists of postal codes into separate rows\n",
    "canadianrentB_df = canadianrentB_df.dropna(subset=['Postal_Code'])\n",
    "canadianrentB_df['Postal_Code'] = canadianrentB_df['Postal_Code'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "canadianrentB_df = canadianrentB_df.explode('Postal_Code').reset_index(drop=True)\n",
    "\n",
    "# Keep only 'City', 'Postal_Code', and rent columns to finalize the dataframe\n",
    "canadianrentB_df = canadianrentB_df[['City', 'Postal_Code'] + rent_columns]\n",
    "print(canadianrentB_df.shape)\n",
    "canadianrentB_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bade08-72f4-42ee-816c-d5fcb07a26e2",
   "metadata": {},
   "source": [
    "In this process, we filter on the data we want to connect later to our main dataframe and we fill on the missing gaps. To do so, we first focus on calculating average rents based on postal codes for different property types (studio, 1-bedroom, 2-bedroom, and 3-bedroom units). For rows with complete data (no missing values), we calculate \"factors\" for each rent type by dividing the rent for each unit type by the overall average rent for that row. These factors are then averaged across all valid rows to create a set of reference factors. For rows with missing rent data, we estimate the missing values using the row-specific average (based on available rent data) and the predefined factors. Finally, the missing values are filled in and the data is rounded for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8af8748-e43f-4d37-a67f-fd92d78388f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighborhood Average Factors:\n",
      "Average factors for Montreal:\n",
      "  Median Rent Studio: 0.71\n",
      "  Median Rent 1 Bedroom: 0.94\n",
      "  Median Rent 2 Bedrooms: 1.07\n",
      "  Median Rent 3 Bedrooms: 1.28\n",
      "Average factors for Ottawa:\n",
      "  Median Rent Studio: 0.73\n",
      "  Median Rent 1 Bedroom: 0.88\n",
      "  Median Rent 2 Bedrooms: 1.09\n",
      "  Median Rent 3 Bedrooms: 1.29\n",
      "Average factors for Quebec City:\n",
      "  Median Rent Studio: 0.79\n",
      "  Median Rent 1 Bedroom: 0.95\n",
      "  Median Rent 2 Bedrooms: 1.07\n",
      "  Median Rent 3 Bedrooms: 1.20\n",
      "Average factors for Toronto:\n",
      "  Median Rent Studio: 0.74\n",
      "  Median Rent 1 Bedroom: 0.89\n",
      "  Median Rent 2 Bedrooms: 1.08\n",
      "  Median Rent 3 Bedrooms: 1.29\n",
      "Average factors for Vancouver:\n",
      "  Median Rent Studio: 0.74\n",
      "  Median Rent 1 Bedroom: 0.85\n",
      "  Median Rent 2 Bedrooms: 1.14\n",
      "  Median Rent 3 Bedrooms: 1.27\n"
     ]
    }
   ],
   "source": [
    "# Ensure rent columns are numeric\n",
    "canadianrentN_df[rent_columns] = canadianrentN_df[rent_columns].apply(pd.to_numeric, errors = 'coerce')\n",
    "canadianrentB_df[rent_columns] = canadianrentB_df[rent_columns].apply(pd.to_numeric, errors = 'coerce')\n",
    "\n",
    "# Group by specified columns and calculate mean for rent columns\n",
    "canadianrentN_df = canadianrentN_df.groupby(['City', 'Postal_Code'], as_index = False).mean()\n",
    "canadianrentB_df = canadianrentB_df.groupby(['City', 'Postal_Code'], as_index = False).mean()\n",
    "\n",
    "# Define a helper function to compute average factors\n",
    "def calculate_avg_factors(df):    \n",
    "    # Drop rows with NaN values in any rent columns\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.dropna(subset = rent_columns)\n",
    "    \n",
    "    # Calculate average rent for each row\n",
    "    df_copy['Average Rent'] = df_copy[rent_columns].mean(axis=1)\n",
    "    \n",
    "    # Compute factors and average factors for each city\n",
    "    avg_factors = {}\n",
    "    for city in df_copy['City'].unique():\n",
    "        city_df_copy = df_copy[df_copy['City'] == city]\n",
    "        avg_factors[city] = {f\"{rent_col}\": (city_df_copy[rent_col] / city_df_copy['Average Rent']).mean() \n",
    "                             for rent_col in rent_columns}\n",
    "    return avg_factors\n",
    "    \n",
    "# Calculate the average factors for both Neighborhood and Borough DataFrames\n",
    "avgN_factors = calculate_avg_factors(canadianrentN_df)\n",
    "avgB_factors = calculate_avg_factors(canadianrentB_df)\n",
    "\n",
    "# Print the results\n",
    "print(\"Neighborhood Average Factors:\")\n",
    "for city, factors in avgN_factors.items():\n",
    "    print(f\"Average factors for {city}:\")\n",
    "    for factor_name, average in factors.items():\n",
    "        print(f\"  {factor_name}: {average:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb4b232-dfd7-4211-88b4-a6c073b8b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute row-specific averages and fill missing values\n",
    "def fill_missing_rents_row_based(row, city_avg_factors):\n",
    "    # Calculate row-specific averages based on available rents\n",
    "    available_rent_averages = [row[col] / city_avg_factors[col] for col in rent_columns if pd.notna(row[col])]\n",
    "    # Calculate the mean of the available row-specific averages\n",
    "    if available_rent_averages:\n",
    "        row_avg = sum(available_rent_averages) / len(available_rent_averages)\n",
    "        # Fill missing rent values using the row-specific average and factors\n",
    "        for col in rent_columns:\n",
    "            if pd.isna(row[col]):\n",
    "                row[col] = row_avg * city_avg_factors[col]\n",
    "    return row\n",
    "\n",
    "# Main function to apply filling process for each DataFrame\n",
    "def fill_missing_rents(df, avg_factors):\n",
    "    df = df.apply(lambda row: fill_missing_rents_row_based(row, avg_factors[row['City']]), axis=1)\n",
    "    df[rent_columns] = df[rent_columns].round(0)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# Apply to both DataFrames\n",
    "canadianrentN_df = fill_missing_rents(canadianrentN_df, avgN_factors)\n",
    "canadianrentB_df = fill_missing_rents(canadianrentB_df, avgB_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee371c42-9907-4ca1-b103-86ab1fd683e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the neighborhoods median rents into the main dataframe \n",
    "cities_df = cities_df.merge(canadianrentN_df.drop(columns='City'), how='left', left_on='Postalcode', right_on='Postal_Code').drop(columns='Postal_Code')\n",
    "\n",
    "# Fill the missing median rents from the main dataframe with the borough median rents\n",
    "for column in rent_columns:\n",
    "    if column in canadianrentB_df.columns:\n",
    "        # Merge only the specific rent column from `canadianrentB_df`\n",
    "        merged_column = cities_df[['Postalcode', column]].set_index('Postalcode').combine_first(canadianrentB_df.set_index('Postal_Code')[[column]])\n",
    "        # Update only NaN values in cities_df using merged_column\n",
    "        cities_df[column] = cities_df[column].fillna(merged_column[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e098725-3c3a-4226-bbc9-9456e6700c18",
   "metadata": {},
   "source": [
    "## [4] Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd74bada-a04c-423f-b1ec-368d9a837d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as 'canadianrent_df_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a CSV file with UTF-8 encoding\n",
    "cities_df.to_csv('canadianrent_df_output.csv', index=False, encoding='utf-8')\n",
    "print(\"DataFrame saved as 'canadianrent_df_output.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
